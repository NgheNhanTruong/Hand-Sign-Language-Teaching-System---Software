{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3b7c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Ghi chú cài đặt thư viện \n",
    "    B1: https://github.com/jeffheaton/t81_558_deep_learning/blob/master/install/tensorflow-install-jul-2020.ipynb\n",
    "    B2: https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/install.html\n",
    "    B3: Install Pyaudio through a file\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7f16bf",
   "metadata": {},
   "source": [
    "# 1. Add library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a74161c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "import mediapipe as mp\n",
    "import tensorflow as tf\n",
    "# of object_detection\n",
    "from object_detection.utils import config_util\n",
    "from object_detection.protos import pipeline_pb2\n",
    "from google.protobuf import text_format\n",
    "import os\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "from object_detection.builders import model_builder\n",
    "import six\n",
    "import sys\n",
    "import serial\n",
    "from serial import Serial\n",
    "import numpy as np\n",
    "from PyQt5 import QtGui, QtCore\n",
    "from PyQt5.QtCore import QThread, pyqtSignal, Qt\n",
    "from PyQt5.QtGui import QPixmap,QImage\n",
    "from PyQt5.QtWidgets import QApplication, QMainWindow,QFileDialog, QMessageBox, QLabel\n",
    "from Giao_dien_test import Ui_MainWindow\n",
    "from PyQt5 import QtWidgets\n",
    "from Sub_page_5_nckh import Ui_Form\n",
    "import speech_recognition\n",
    "from decimal import Decimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dbdbc9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import các thư viện cho model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GRU, Dense, Flatten,Dropout\n",
    "from tensorflow.keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d645024",
   "metadata": {},
   "source": [
    "# 2.Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c88f4e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ACTION RECOGNITION\n",
    "mp_holistic = mp.solutions.holistic # Holistic model\n",
    "mp_drawing = mp.solutions.drawing_utils # Drawing utilities\n",
    "def mediapipe_detection(image, model):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # COLOR CONVERSION BGR 2 RGB\n",
    "    image.flags.writeable = False                  # Image is no longer writeable\n",
    "    results = model.process(image)                 # Make prediction\n",
    "    image.flags.writeable = True                   # Image is now writeable \n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR) # COLOR COVERSION RGB 2 BGR\n",
    "    return image, results\n",
    "def draw_landmarks(image, results):\n",
    "    mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS) # Draw right hand connections\n",
    "def draw_styled_landmarks(image, results):\n",
    "    # Draw right hand connections  \n",
    "    mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                             mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4), \n",
    "                             mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n",
    "                             )\n",
    "def extract_keypoints(results):\n",
    "    rh = np.array([[res.x, res.y, res.z] for res in results.right_hand_landmarks.landmark]).flatten() if results.right_hand_landmarks else np.zeros(21*3)\n",
    "    return np.concatenate([rh])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "679f184d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vẽ chữ stop lên màn hình\n",
    "def draw_class_on_image(label,img):\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    bottomLeftCornerOfText = (120,200)\n",
    "    fontScale = 5\n",
    "    fontColor = (20,20,200)\n",
    "    thichkness=8\n",
    "    lineType=2\n",
    "    cv2.putText(img,label,\n",
    "               bottomLeftCornerOfText,\n",
    "               font,\n",
    "               fontScale,\n",
    "               fontColor,\n",
    "               thichkness,\n",
    "               lineType)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ad6b927",
   "metadata": {},
   "outputs": [],
   "source": [
    "#khai báo các classes\n",
    "actions = np.array([  \"aw\",\"ee\",\"ow\",\"sac\", \"hoi\",\"nang\",\"nothing\",\"aa\",\"oo\",\"uw\", \"nga\",\"huyen\" ])\n",
    "log_dir = os.path.join('Logs_file\\Logs_8_5\\Logs_GRU_8_5')\n",
    "tb_callback = TensorBoard(log_dir=log_dir)\n",
    "# cấu trúc model LSTM\n",
    "model = Sequential()\n",
    "model.add(GRU(units=256, return_sequences=True, input_shape=(30,63)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(GRU(units=128, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(actions.shape[0], activation='softmax'))\n",
    "#compile model \n",
    "model.compile(optimizer='Adam', loss=tf.keras.losses.MeanSquaredError(), metrics=['categorical_accuracy'])\n",
    "#load model weight\n",
    "model.load_weights('Model_file\\Model_8_5\\Model_GRU_8_5.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "803f7c4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x13221808b88>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# OF OBJECT DETECTION\n",
    "import time\n",
    "WORKSPACE_PATH = 'Tensorflow/workspace'\n",
    "SCRIPTS_PATH = 'Tensorflow/scripts'\n",
    "APIMODEL_PATH = 'Tensorflow/models'\n",
    "ANNOTATION_PATH = WORKSPACE_PATH+'/annotations'\n",
    "IMAGE_PATH = WORKSPACE_PATH+'/images'\n",
    "MODEL_PATH = WORKSPACE_PATH+'/models'\n",
    "PRETRAINED_MODEL_PATH = WORKSPACE_PATH+'/pre-trained-models'\n",
    "CONFIG_PATH = MODEL_PATH+'/my_ssd_mobnet/pipeline.config'\n",
    "CHECKPOINT_PATH = MODEL_PATH+'/my_ssd_mobnet/'\n",
    "\n",
    "labels = [\n",
    "        {'name':'A', 'id':1},\n",
    "        {'name':'B', 'id':2},\n",
    "        {'name':'C', 'id':3},\n",
    "        {'name':'D', 'id':4},\n",
    "        {'name':'E', 'id':5}]\n",
    "\n",
    "CUSTOM_MODEL_NAME = 'my_ssd_mobnet' \n",
    "\n",
    "CONFIG_PATH = MODEL_PATH+'/'+CUSTOM_MODEL_NAME+'/pipeline.config'\n",
    "\n",
    "# Load pipeline config and build a detection model\n",
    "configs = config_util.get_configs_from_pipeline_file(CONFIG_PATH)\n",
    "detection_model = model_builder.build(model_config=configs['model'], is_training=False)\n",
    "\n",
    "# Restore checkpoint\n",
    "ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n",
    "ckpt.restore(os.path.join(CHECKPOINT_PATH, 'ckpt-11')).expect_partial()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b82a7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def detect_fn(image):\n",
    "    image, shapes = detection_model.preprocess(image)\n",
    "    prediction_dict = detection_model.predict(image, shapes)\n",
    "    detections = detection_model.postprocess(prediction_dict, shapes)\n",
    "    return detections,prediction_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16126ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "serialcom = serial.Serial('COM7',9600) #mở serial ở cổng số 3, Rbaud = 9600\n",
    "serialcom.timeout = 1\n",
    "\n",
    "class MainWindow(QMainWindow):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.uic = Ui_MainWindow()\n",
    "        self.uic.setupUi(self)\n",
    "        self.trangthai = False\n",
    "        self.object_detection = True\n",
    "        self.action_recognition = False\n",
    "        self.cau_hoi_hien_tai = 0\n",
    "        self.uic.label_10.setAlignment(QtCore.Qt.AlignCenter)\n",
    "        # khai bao nut nhan\n",
    "            #các nút chọn page chế dộ\n",
    "        self.uic.pushButton.clicked.connect(self.page_chon_che_do)\n",
    "        self.uic.pushButton_3.clicked.connect(self.page_hoc_chu) \n",
    "        self.uic.pushButton_4.clicked.connect(self.page_kiem_tra)\n",
    "        self.uic.pushButton_5.clicked.connect(self.page_phien_dich)\n",
    "        \n",
    "            #các home khác nhau\n",
    "        self.uic.pushButton_13.clicked.connect(self.page_chon_che_do) #nút home page học chữ\n",
    "        self.uic.pushButton_54.clicked.connect(self.page_chon_che_do)#nút home page phiên dịch\n",
    "\n",
    "        self.uic.pushButton_32.clicked.connect(self.stop_video_in_page_chon_che_do) #nút home page kiểm tra\n",
    "\n",
    "        self.uic.pushButton_52.clicked.connect(self.open_sub_page_5)  #nút thu giọng nói\n",
    "        self.uic.pushButton_53.clicked.connect(self.close_sub_page_5) #nút mã hóa và gửi dữ liệu cho arduino\n",
    "\n",
    "        #Khai báo chữ cái\n",
    "        self.uic.pushButton_2.clicked.connect(self.Gui_chu_A)\n",
    "        self.uic.pushButton_33.clicked.connect(self.Gui_chu_AW)\n",
    "        self.uic.pushButton_41.clicked.connect(self.Gui_chu_AA)\n",
    "        self.uic.pushButton_7.clicked.connect(self.Gui_chu_B)\n",
    "        self.uic.pushButton_8.clicked.connect(self.Gui_chu_C)\n",
    "        self.uic.pushButton_6.clicked.connect(self.Gui_chu_D)\n",
    "        self.uic.pushButton_42.clicked.connect(self.Gui_chu_DD)\n",
    "        self.uic.pushButton_9.clicked.connect(self.Gui_chu_E)\n",
    "        self.uic.pushButton_43.clicked.connect(self.Gui_chu_EE)\n",
    "        self.uic.pushButton_10.clicked.connect(self.Gui_chu_G)\n",
    "        self.uic.pushButton_11.clicked.connect(self.Gui_chu_H)\n",
    "        self.uic.pushButton_12.clicked.connect(self.Gui_chu_I)\n",
    "        self.uic.pushButton_15.clicked.connect(self.Gui_chu_K)\n",
    "        self.uic.pushButton_19.clicked.connect(self.Gui_chu_L)\n",
    "        self.uic.pushButton_17.clicked.connect(self.Gui_chu_M)\n",
    "        self.uic.pushButton_20.clicked.connect(self.Gui_chu_N)\n",
    "        self.uic.pushButton_18.clicked.connect(self.Gui_chu_O)\n",
    "        self.uic.pushButton_44.clicked.connect(self.Gui_chu_OO)\n",
    "        self.uic.pushButton_45.clicked.connect(self.Gui_chu_OW)\n",
    "        self.uic.pushButton_21.clicked.connect(self.Gui_chu_P)\n",
    "        self.uic.pushButton_16.clicked.connect(self.Gui_chu_Q)\n",
    "        self.uic.pushButton_14.clicked.connect(self.Gui_chu_R)\n",
    "        self.uic.pushButton_38.clicked.connect(self.Gui_chu_S)\n",
    "        self.uic.pushButton_22.clicked.connect(self.Gui_chu_T)\n",
    "        self.uic.pushButton_31.clicked.connect(self.Gui_chu_U)\n",
    "        self.uic.pushButton_46.clicked.connect(self.Gui_chu_UW)\n",
    "        self.uic.pushButton_28.clicked.connect(self.Gui_chu_V)\n",
    "        self.uic.pushButton_34.clicked.connect(self.Gui_chu_X)\n",
    "        self.uic.pushButton_27.clicked.connect(self.Gui_chu_Y)\n",
    "        self.uic.pushButton_47.clicked.connect(self.Gui_chu_sac)\n",
    "        self.uic.pushButton_48.clicked.connect(self.Gui_chu_huyen)\n",
    "        self.uic.pushButton_49.clicked.connect(self.Gui_chu_hoi)\n",
    "        self.uic.pushButton_50.clicked.connect(self.Gui_chu_nga)\n",
    "        self.uic.pushButton_51.clicked.connect(self.Gui_chu_nang)\n",
    "\n",
    "        #khai bao cac chu so\n",
    "        self.uic.pushButton_36.clicked.connect(self.Gui_so_0)\n",
    "        self.uic.pushButton_25.clicked.connect(self.Gui_so_1)\n",
    "        self.uic.pushButton_29.clicked.connect(self.Gui_so_2)\n",
    "        self.uic.pushButton_30.clicked.connect(self.Gui_so_3)\n",
    "        self.uic.pushButton_23.clicked.connect(self.Gui_so_4)\n",
    "        self.uic.pushButton_26.clicked.connect(self.Gui_so_5)\n",
    "        self.uic.pushButton_35.clicked.connect(self.Gui_so_6)\n",
    "        self.uic.pushButton_37.clicked.connect(self.Gui_so_7)\n",
    "        self.uic.pushButton_40.clicked.connect(self.Gui_so_8)\n",
    "        self.uic.pushButton_39.clicked.connect(self.Gui_so_9)\n",
    "\n",
    "\n",
    "        #page 4\n",
    "        self.uic.pushButton_24.clicked.connect(self.Chuong_trinh_nhan_dien) #mở đề kiểm tra\n",
    "        self.thread = {} #ban đầu ko có luồng nào chạy riêng \n",
    "        \n",
    "    #Hàm thông báo thoát khỏi giao diện \n",
    "    def closeEvent(self, event):\n",
    "        if self.trangthai == True:\n",
    "            self.stop_capture_video()\n",
    "            self.trangthai = False\n",
    "        reply = QMessageBox.question(self, 'Thoát chương trình', 'Bạn có chắc chắn muốn thoát chương trình không?',\n",
    "                                     QMessageBox.Yes | QMessageBox.No, QMessageBox.No)\n",
    "        if reply == QMessageBox.Yes:\n",
    "            event.accept()\n",
    "            print('Thoát chương trình')\n",
    "        else:\n",
    "            event.ignore()\n",
    "            \n",
    "    # các lệnh mở page\n",
    "    def page_chon_che_do(self):\n",
    "        self.uic.stackedWidget.setCurrentWidget(self.uic.page_2)\n",
    "    def page_hoc_chu(self):\n",
    "        self.uic.stackedWidget.setCurrentWidget(self.uic.page_3)\n",
    "    def page_kiem_tra(self):\n",
    "        self.uic.stackedWidget.setCurrentWidget(self.uic.page_4)\n",
    "    def page_phien_dich(self):\n",
    "        self.uic.stackedWidget.setCurrentWidget(self.uic.page_5)\n",
    "    def open_sub_page_5(self):\n",
    "        # mở màn hình nhỏ hiện chữ đang ghi âm\n",
    "        self.Second_window = QtWidgets.QMainWindow()\n",
    "        self.uic1 = Ui_Form()\n",
    "        self.uic1.setupUi(self.Second_window)\n",
    "        self.Second_window.show()\n",
    "        # chạy đa luồng, ghi âm\n",
    "        self.thread[2] = speech_to_text(index=2)\n",
    "        self.thread[2].start() #kích hoạt luồng 2 mở\n",
    "        self.thread[2].signal_2.connect(self.show_text_from_speech) \n",
    "\n",
    "    \n",
    "    def show_text_from_speech(self, text):\n",
    "        TEXT = text\n",
    "        if TEXT != \"\":\n",
    "            print(TEXT)\n",
    "            self.uic.label_10.setText(TEXT)\n",
    "            self.Second_window.close()\n",
    "            self.thread[2].stop()\n",
    "            \n",
    "    def close_sub_page_5(self):\n",
    "        pass\n",
    "\n",
    "    #Gửi các chữ cái\n",
    "    def Gui_chu_A(self):\n",
    "        self.uic.label_4.setPixmap(QPixmap('Chu_cai_va_so/a_2.png'))\n",
    "        gia_tri_serial = \"a\"\n",
    "        print(gia_tri_serial)\n",
    "        serialcom.write(gia_tri_serial.encode()) #mã hóa dữ liệu và gửi đi\n",
    "    def Gui_chu_AW(self):\n",
    "        self.uic.label_4.setPixmap(QPixmap('Chu_cai_va_so/ă.png'))\n",
    "        gia_tri_serial = \"aw\"\n",
    "        print(gia_tri_serial)\n",
    "        serialcom.write(gia_tri_serial.encode())\n",
    "    def Gui_chu_AA(self):\n",
    "        self.uic.label_4.setPixmap(QPixmap('Chu_cai_va_so/â_2.png'))\n",
    "        gia_tri_serial = \"aa\"\n",
    "        print(gia_tri_serial)\n",
    "        serialcom.write(gia_tri_serial.encode())\n",
    "    def Gui_chu_B(self):\n",
    "        self.uic.label_4.setPixmap(QPixmap('Chu_cai_va_so/b.png'))\n",
    "        gia_tri_serial = \"b\"\n",
    "        print(gia_tri_serial)\n",
    "        serialcom.write(gia_tri_serial.encode())\n",
    "    def Gui_chu_C(self):\n",
    "        self.uic.label_4.setPixmap(QPixmap('Chu_cai_va_so/c.png'))\n",
    "        gia_tri_serial = \"c\"\n",
    "        print(gia_tri_serial)\n",
    "        serialcom.write(gia_tri_serial.encode())\n",
    "    def Gui_chu_D(self):\n",
    "        self.uic.label_4.setPixmap(QPixmap('Chu_cai_va_so/d.png'))\n",
    "        gia_tri_serial = \"d\"\n",
    "        print(gia_tri_serial)\n",
    "        serialcom.write(gia_tri_serial.encode())\n",
    "    def Gui_chu_DD(self):\n",
    "        self.uic.label_4.setPixmap(QPixmap('Chu_cai_va_so/đ.png'))\n",
    "        gia_tri_serial = \"dd\"\n",
    "        print(gia_tri_serial)\n",
    "        serialcom.write(gia_tri_serial.encode())\n",
    "    def Gui_chu_E(self):\n",
    "        self.uic.label_4.setPixmap(QPixmap('Chu_cai_va_so/e.png'))\n",
    "        gia_tri_serial = \"e\"\n",
    "        print(gia_tri_serial)\n",
    "        serialcom.write(gia_tri_serial.encode())\n",
    "    def Gui_chu_EE(self):\n",
    "        self.uic.label_4.setPixmap(QPixmap('Chu_cai_va_so/ê.png'))\n",
    "        gia_tri_serial = \"ee\"\n",
    "        print(gia_tri_serial)\n",
    "        serialcom.write(gia_tri_serial.encode())\n",
    "    def Gui_chu_G(self):\n",
    "        self.uic.label_4.setPixmap(QPixmap('Chu_cai_va_so/g.png'))\n",
    "        gia_tri_serial = \"g\"\n",
    "        print(gia_tri_serial)\n",
    "        serialcom.write(gia_tri_serial.encode())\n",
    "    def Gui_chu_H(self):\n",
    "        self.uic.label_4.setPixmap(QPixmap('Chu_cai_va_so/h.png'))\n",
    "        gia_tri_serial = \"h\"\n",
    "        print(gia_tri_serial)\n",
    "        serialcom.write(gia_tri_serial.encode())\n",
    "    def Gui_chu_I(self):\n",
    "        self.uic.label_4.setPixmap(QPixmap('Chu_cai_va_so/i.png'))\n",
    "        gia_tri_serial = \"i\"\n",
    "        print(gia_tri_serial)\n",
    "        serialcom.write(gia_tri_serial.encode())\n",
    "    def Gui_chu_K(self):\n",
    "        self.uic.label_4.setPixmap(QPixmap('Chu_cai_va_so/k.png'))\n",
    "        gia_tri_serial = \"k\"\n",
    "        print(gia_tri_serial)\n",
    "        serialcom.write(gia_tri_serial.encode())\n",
    "    def Gui_chu_L(self):\n",
    "        self.uic.label_4.setPixmap(QPixmap('Chu_cai_va_so/l.png'))\n",
    "        gia_tri_serial = \"l\"\n",
    "        print(gia_tri_serial)\n",
    "        serialcom.write(gia_tri_serial.encode())\n",
    "    def Gui_chu_M(self):\n",
    "        self.uic.label_4.setPixmap(QPixmap('Chu_cai_va_so/m.png'))\n",
    "        gia_tri_serial = \"m\"\n",
    "        print(gia_tri_serial)\n",
    "        serialcom.write(gia_tri_serial.encode())\n",
    "    def Gui_chu_N(self):\n",
    "        self.uic.label_4.setPixmap(QPixmap('Chu_cai_va_so/n.png'))\n",
    "        gia_tri_serial = \"n\"\n",
    "        print(gia_tri_serial)\n",
    "        serialcom.write(gia_tri_serial.encode())\n",
    "    def Gui_chu_O(self):\n",
    "        self.uic.label_4.setPixmap(QPixmap('Chu_cai_va_so/o.png'))\n",
    "        gia_tri_serial = \"o\"\n",
    "        print(gia_tri_serial)\n",
    "        serialcom.write(gia_tri_serial.encode())\n",
    "    def Gui_chu_OW(self):\n",
    "        self.uic.label_4.setPixmap(QPixmap('Chu_cai_va_so/ơ.png'))\n",
    "        gia_tri_serial = \"ow\"\n",
    "        print(gia_tri_serial)\n",
    "        serialcom.write(gia_tri_serial.encode())\n",
    "    def Gui_chu_OO(self):\n",
    "        self.uic.label_4.setPixmap(QPixmap('Chu_cai_va_so/ô.png'))\n",
    "        gia_tri_serial = \"oo\"\n",
    "        print(gia_tri_serial)\n",
    "        serialcom.write(gia_tri_serial.encode())\n",
    "    def Gui_chu_P(self):\n",
    "        self.uic.label_4.setPixmap(QPixmap('Chu_cai_va_so/p.png'))\n",
    "        gia_tri_serial = \"p\"\n",
    "        print(gia_tri_serial)\n",
    "        serialcom.write(gia_tri_serial.encode())\n",
    "    def Gui_chu_Q(self):\n",
    "        self.uic.label_4.setPixmap(QPixmap('Chu_cai_va_so/q.png'))\n",
    "        gia_tri_serial = \"q\"\n",
    "        print(gia_tri_serial)\n",
    "        serialcom.write(gia_tri_serial.encode())\n",
    "    def Gui_chu_R(self):\n",
    "        self.uic.label_4.setPixmap(QPixmap('Chu_cai_va_so/r.png'))\n",
    "        gia_tri_serial = \"r\"\n",
    "        print(gia_tri_serial)\n",
    "        serialcom.write(gia_tri_serial.encode())\n",
    "    def Gui_chu_S(self):\n",
    "        self.uic.label_4.setPixmap(QPixmap('Chu_cai_va_so/s.png'))\n",
    "        gia_tri_serial = \"s\"\n",
    "        print(gia_tri_serial)\n",
    "        serialcom.write(gia_tri_serial.encode())\n",
    "    def Gui_chu_T(self):\n",
    "        self.uic.label_4.setPixmap(QPixmap('Chu_cai_va_so/t.png'))\n",
    "        gia_tri_serial = \"t\"\n",
    "        print(gia_tri_serial)\n",
    "        serialcom.write(gia_tri_serial.encode())\n",
    "    def Gui_chu_U(self):\n",
    "        self.uic.label_4.setPixmap(QPixmap('Chu_cai_va_so/u.png'))\n",
    "        gia_tri_serial = \"u\"\n",
    "        print(gia_tri_serial)\n",
    "        serialcom.write(gia_tri_serial.encode())\n",
    "    def Gui_chu_UW(self):\n",
    "        self.uic.label_4.setPixmap(QPixmap('Chu_cai_va_so/ư.png'))\n",
    "        gia_tri_serial = \"uw\"\n",
    "        print(gia_tri_serial)\n",
    "        serialcom.write(gia_tri_serial.encode())\n",
    "    def Gui_chu_V(self):\n",
    "        self.uic.label_4.setPixmap(QPixmap('Chu_cai_va_so/v.png'))\n",
    "        gia_tri_serial = \"v\"\n",
    "        print(gia_tri_serial)\n",
    "        serialcom.write(gia_tri_serial.encode())\n",
    "    def Gui_chu_X(self):\n",
    "        self.uic.label_4.setPixmap(QPixmap('Chu_cai_va_so/x.png'))\n",
    "        gia_tri_serial = \"x\"\n",
    "        print(gia_tri_serial)\n",
    "        serialcom.write(gia_tri_serial.encode())\n",
    "    def Gui_chu_Y(self):\n",
    "        self.uic.label_4.setPixmap(QPixmap('Chu_cai_va_so/y.png'))\n",
    "        gia_tri_serial = \"y\"\n",
    "        print(gia_tri_serial)\n",
    "        serialcom.write(gia_tri_serial.encode())\n",
    "    def Gui_chu_sac(self):\n",
    "        self.uic.label_4.setPixmap(QPixmap('Chu_cai_va_so/dau sac.png'))\n",
    "        gia_tri_serial = \"sac\"\n",
    "        print(gia_tri_serial)\n",
    "        serialcom.write(gia_tri_serial.encode())\n",
    "    def Gui_chu_huyen(self):\n",
    "        self.uic.label_4.setPixmap(QPixmap('Chu_cai_va_so/dau huyen.png'))\n",
    "        gia_tri_serial = \"huyen\"\n",
    "        print(gia_tri_serial)\n",
    "        serialcom.write(gia_tri_serial.encode())\n",
    "    def Gui_chu_hoi(self):\n",
    "        self.uic.label_4.setPixmap(QPixmap('Chu_cai_va_so/dau hoi.png'))\n",
    "        gia_tri_serial = \"hoi\"\n",
    "        print(gia_tri_serial)\n",
    "        serialcom.write(gia_tri_serial.encode())\n",
    "    def Gui_chu_nga(self):\n",
    "        self.uic.label_4.setPixmap(QPixmap('Chu_cai_va_so/dau ngã.png'))\n",
    "        gia_tri_serial = \"nga\"\n",
    "        print(gia_tri_serial)\n",
    "        serialcom.write(gia_tri_serial.encode())\n",
    "    def Gui_chu_nang(self):\n",
    "        self.uic.label_4.setPixmap(QPixmap(\"Chu_cai_va_so/dau nang.png\"))\n",
    "        gia_tri_serial = \"nang\"\n",
    "        print(gia_tri_serial)\n",
    "        serialcom.write(gia_tri_serial.encode())\n",
    "\n",
    "    #Gửi các chữ số\n",
    "    def Gui_so_0(self):\n",
    "        self.uic.label_4.setPixmap(QPixmap(\"Chu_cai_va_so/0.png\"))\n",
    "        gia_tri_serial = \"0\"\n",
    "        print(gia_tri_serial)\n",
    "        serialcom.write(gia_tri_serial.encode())\n",
    "    def Gui_so_1(self):\n",
    "        self.uic.label_4.setPixmap(QPixmap(\"Chu_cai_va_so/1.png\"))\n",
    "        gia_tri_serial = \"1\"\n",
    "        print(gia_tri_serial)\n",
    "        serialcom.write(gia_tri_serial.encode())\n",
    "    def Gui_so_2(self):\n",
    "        self.uic.label_4.setPixmap(QPixmap(\"Chu_cai_va_so/2.png\"))\n",
    "        gia_tri_serial = \"2\"\n",
    "        print(gia_tri_serial)\n",
    "        serialcom.write(gia_tri_serial.encode())\n",
    "    def Gui_so_3(self):\n",
    "        self.uic.label_4.setPixmap(QPixmap(\"Chu_cai_va_so/3.png\"))\n",
    "        gia_tri_serial = \"3\"\n",
    "        print(gia_tri_serial)\n",
    "        serialcom.write(gia_tri_serial.encode())\n",
    "    def Gui_so_4(self):\n",
    "        self.uic.label_4.setPixmap(QPixmap(\"Chu_cai_va_so/4.png\"))\n",
    "        gia_tri_serial = \"4\"\n",
    "        print(gia_tri_serial)\n",
    "        serialcom.write(gia_tri_serial.encode())\n",
    "    def Gui_so_5(self):\n",
    "        self.uic.label_4.setPixmap(QPixmap(\"Chu_cai_va_so/5.png\"))\n",
    "        gia_tri_serial = \"5\"\n",
    "        print(gia_tri_serial)\n",
    "        serialcom.write(gia_tri_serial.encode())\n",
    "    def Gui_so_6(self):\n",
    "        self.uic.label_4.setPixmap(QPixmap(\"Chu_cai_va_so/6.png\"))\n",
    "        gia_tri_serial = \"6\"\n",
    "        print(gia_tri_serial)\n",
    "        serialcom.write(gia_tri_serial.encode())\n",
    "    def Gui_so_7(self):\n",
    "        self.uic.label_4.setPixmap(QPixmap(\"Chu_cai_va_so/7.png\"))\n",
    "        gia_tri_serial = \"7\"\n",
    "        print(gia_tri_serial)\n",
    "        serialcom.write(gia_tri_serial.encode())\n",
    "    def Gui_so_8(self):\n",
    "        self.uic.label_4.setPixmap(QPixmap(\"Chu_cai_va_so/8.png\"))\n",
    "        gia_tri_serial = \"8\"\n",
    "        print(gia_tri_serial)\n",
    "        serialcom.write(gia_tri_serial.encode())\n",
    "    def Gui_so_9(self):\n",
    "        self.uic.label_4.setPixmap(QPixmap(\"Chu_cai_va_so/9.png\"))\n",
    "        gia_tri_serial = \"9\"\n",
    "        print(gia_tri_serial)\n",
    "        serialcom.write(gia_tri_serial.encode())\n",
    "\n",
    "\n",
    "    #page 4\n",
    "    def stop_capture_video(self):\n",
    "        self.thread[1].stop()\n",
    "        \n",
    "    def stop_video_in_page_chon_che_do(self):\n",
    "        self.uic.stackedWidget.setCurrentWidget(self.uic.page_2)\n",
    "        if self.trangthai == True:        #nếu đang bật nhận diện \n",
    "            self.stop_capture_video()     #dừng luồng nhận diện\n",
    "            self.trangthai = False #trạng thái bật nhận diện = false\n",
    "                \n",
    "    def Chuong_trinh_nhan_dien(self):   \n",
    "        if (self.object_detection == True) & (self.action_recognition == False):\n",
    "            self.thread[1] = capture_video(index=1)\n",
    "            self.thread[1].start()\n",
    "            self.thread[1].signal.connect(self.show_wedcam) # tín hiệu gửi về là hình đã vẽ bouding box, đưa hình đó qua hàm show_webcam\n",
    "            self.thread[1].signal_1.connect(self.phan_loai_so_tt)\n",
    "        elif (self.object_detection == False) & (self.action_recognition == True):\n",
    "            self.thread[1].stop()\n",
    "            self.thread[5] = mediapipe_capture(index=5)\n",
    "            self.thread[5].start()\n",
    "            self.thread[5].signal_5.connect(self.show_wedcam) # tín hiệu gửi về là hình có các keypoint, đưa hình đó qua hàm show_webcam\n",
    "            self.thread[5].signal_5_1.connect(self.phan_loai_so_tt)\n",
    "        self.trangthai = True\n",
    "    \n",
    "    # Hàm để chạy tính thời gian, nếu trả lời đúng sau 4s thì mới chuyển câu hỏi mới\n",
    "    def Time_count (self):\n",
    "        self.thread[4] = Timer_4s(index=4)\n",
    "        self.thread[4].start()\n",
    "        self.thread[4].signal_4.connect(self.chuyen_cau_hoi)\n",
    "\n",
    "    def show_wedcam(self, cv_img):\n",
    "        \"\"\"Updates the image_label with a new opencv image\"\"\"\n",
    "        qt_img = self.convert_cv_qt(cv_img) #convert lại hình sao cho phù hợp với chuẩn của pyqt5\n",
    "        self.uic.label_7.setPixmap(qt_img)\n",
    "    def phan_loai_so_tt(self, number_question):\n",
    "        if number_question == 1:\n",
    "            self.cau_hoi_hien_tai = 1\n",
    "            self.Time_count()            \n",
    "        if number_question == 2:\n",
    "            self.cau_hoi_hien_tai = 2\n",
    "            self.uic.label_12.setPixmap(QPixmap(\"Chu_cai_va_so/Nut_T4_2.png\"))\n",
    "            self.cau_tra_loi_dung()\n",
    "            self.Time_count()\n",
    "        if number_question == 3:\n",
    "            self.cau_hoi_hien_tai = 3\n",
    "            self.uic.label_13.setPixmap(QPixmap(\"Chu_cai_va_so/Nut_T4_2.png\"))\n",
    "            self.cau_tra_loi_dung()\n",
    "            self.Time_count()\n",
    "        if number_question == 4:\n",
    "            self.cau_hoi_hien_tai = 4\n",
    "            self.uic.label_14.setPixmap(QPixmap(\"Chu_cai_va_so/Nut_T4_2.png\"))\n",
    "            self.cau_tra_loi_dung()\n",
    "            self.Time_count()\n",
    "        if number_question == 5:\n",
    "            self.cau_hoi_hien_tai = 5\n",
    "            self.uic.label_15.setPixmap(QPixmap(\"Chu_cai_va_so/Nut_T4_2.png\"))\n",
    "            self.cau_tra_loi_dung()\n",
    "            self.Time_count()\n",
    "        if number_question == 6:\n",
    "            self.cau_hoi_hien_tai = 6\n",
    "            self.uic.label_16.setPixmap(QPixmap(\"Chu_cai_va_so/Nut_T4_2.png\"))\n",
    "            self.cau_tra_loi_dung()\n",
    "            self.Time_count()     \n",
    "        if number_question == 7:\n",
    "            self.cau_hoi_hien_tai =7\n",
    "            self.uic.label_17.setPixmap(QPixmap(\"Chu_cai_va_so/Nut_T4_2.png\"))\n",
    "            self.cau_tra_loi_dung()\n",
    "            self.Time_count()            \n",
    "        if number_question == 8:\n",
    "            self.cau_hoi_hien_tai = 8\n",
    "            self.uic.label_18.setPixmap(QPixmap(\"Chu_cai_va_so/Nut_T4_2.png\"))\n",
    "            self.cau_tra_loi_dung()\n",
    "            self.Time_count()            \n",
    "        if number_question == 9:\n",
    "            self.cau_hoi_hien_tai = 9\n",
    "            self.uic.label_19.setPixmap(QPixmap(\"Chu_cai_va_so/Nut_T4_2.png\"))\n",
    "            self.cau_tra_loi_dung()\n",
    "            self.Time_count()            \n",
    "        if number_question == 10:\n",
    "            self.cau_hoi_hien_tai = 10\n",
    "            self.uic.label_20.setPixmap(QPixmap(\"Chu_cai_va_so/Nut_T4_2.png\"))\n",
    "            self.cau_tra_loi_dung()\n",
    "            self.Time_count()\n",
    "        if number_question == 11:\n",
    "            self.cau_hoi_hien_tai = 11\n",
    "            self.uic.label_21.setPixmap(QPixmap(\"Chu_cai_va_so/Nut_T4_2.png\"))\n",
    "            self.cau_tra_loi_dung()\n",
    "            self.Time_count()\n",
    "        if number_question == 12:\n",
    "            self.cau_hoi_hien_tai = 12\n",
    "            self.uic.label_22.setPixmap(QPixmap(\"Chu_cai_va_so/Nut_T4_2.png\"))\n",
    "            self.cau_tra_loi_dung()\n",
    "            self.Time_count()\n",
    "            \n",
    "\n",
    "\n",
    "    def convert_cv_qt(self, cv_img):\n",
    "        \"\"\"Convert from an opencv image to QPixmap\"\"\"\n",
    "        rgb_image = cv2.cvtColor(cv_img, cv2.COLOR_BGR2RGB)\n",
    "        h, w, ch = rgb_image.shape\n",
    "        bytes_per_line = ch * w\n",
    "        convert_to_Qt_format = QtGui.QImage(rgb_image.data, w, h, bytes_per_line, QtGui.QImage.Format_RGB888)\n",
    "        p = convert_to_Qt_format.scaled(235, 178, Qt.KeepAspectRatio)\n",
    "        return QPixmap.fromImage(p)\n",
    "\n",
    "    def cau_tra_loi_dung(self):\n",
    "        self.thread[3] = show_video_tra_loi_dung(index=3)\n",
    "        self.thread[3].start()\n",
    "        self.thread[3].signal_3.connect(self.show_video)\n",
    "\n",
    "    def show_video(self, cv_vid):\n",
    "        \"\"\"Updates the image_label with a new opencv image\"\"\"\n",
    "        qt_vid = self.convert_video(cv_vid)\n",
    "        self.uic.label_8.setPixmap(qt_vid)\n",
    "\n",
    "\n",
    "    def convert_video(self, cv_vid):\n",
    "        \"\"\"Convert from an opencv image to QPixmap\"\"\"\n",
    "        rgb_image = cv2.cvtColor(cv_vid, cv2.COLOR_BGR2RGB)\n",
    "        h, w, ch = rgb_image.shape\n",
    "        bytes_per_line = ch * w\n",
    "        convert_to_Qt_format = QtGui.QImage(rgb_image.data, w, h, bytes_per_line, QtGui.QImage.Format_RGB888)\n",
    "        p = convert_to_Qt_format.scaled(1282, 462, Qt.KeepAspectRatio)\n",
    "        return QPixmap.fromImage(p)\n",
    "    \n",
    "    \n",
    "    def chuyen_cau_hoi(self, number_signal):\n",
    "        if (number_signal == 111) & (self.cau_hoi_hien_tai == 1) :            \n",
    "            self.uic.label_6.setPixmap(QPixmap(\"Chu_cai_va_so/b.png\"))\n",
    "            self.thread[4].stop()\n",
    "        elif (number_signal == 111):\n",
    "            self.uic.label_6.clear()\n",
    "        if (number_signal == 11) & (self.cau_hoi_hien_tai == 2):            \n",
    "            self.uic.label_6.setPixmap(QPixmap(\"Chu_cai_va_so/c.png\"))\n",
    "            self.thread[4].stop()\n",
    "        if (number_signal == 11) & (self.cau_hoi_hien_tai == 3):            \n",
    "            self.uic.label_6.setPixmap(QPixmap(\"Chu_cai_va_so/a_2.png\"))\n",
    "            self.thread[4].stop()\n",
    "        if (number_signal == 11) & (self.cau_hoi_hien_tai == 4):            \n",
    "            self.uic.label_6.setPixmap(QPixmap(\"Chu_cai_va_so/e.png\"))\n",
    "            self.thread[4].stop()\n",
    "        if (number_signal == 11) & (self.cau_hoi_hien_tai == 5):            \n",
    "            self.uic.label_6.setPixmap(QPixmap(\"Chu_cai_va_so/d.png\"))\n",
    "            self.thread[4].stop()\n",
    "            \n",
    "        \n",
    "        if (number_signal == 11) & (self.cau_hoi_hien_tai == 6):        \n",
    "            self.object_detection = False  \n",
    "            self.action_recognition = True\n",
    "            self.Chuong_trinh_nhan_dien()\n",
    "            self.uic.label_6.setPixmap(QPixmap(\"Chu_cai_va_so/ă.png\"))\n",
    "            print(\"ă\")\n",
    "            self.thread[4].stop()\n",
    "        if (number_signal == 11) & (self.cau_hoi_hien_tai == 7):            \n",
    "            self.uic.label_6.setPixmap(QPixmap(\"Chu_cai_va_so/ê.png\"))\n",
    "            print(\"ê\")\n",
    "            self.thread[4].stop()\n",
    "        if (number_signal == 11) & (self.cau_hoi_hien_tai == 8):            \n",
    "            self.uic.label_6.setPixmap(QPixmap(\"Chu_cai_va_so/ơ.png\"))\n",
    "            print(\"ơ\")\n",
    "            self.thread[4].stop()\n",
    "        if (number_signal == 11) & (self.cau_hoi_hien_tai == 9):            \n",
    "            self.uic.label_6.setPixmap(QPixmap(\"Chu_cai_va_so/dau sac.png\"))\n",
    "            print(\"sắc\")\n",
    "            self.thread[4].stop()\n",
    "        if (number_signal == 11) & (self.cau_hoi_hien_tai == 10):            \n",
    "            self.uic.label_6.setPixmap(QPixmap(\"Chu_cai_va_so/dau hoi.png\"))\n",
    "            print(\"hỏi\")\n",
    "            self.thread[4].stop() \n",
    "        if (number_signal == 11) & (self.cau_hoi_hien_tai == 11):            \n",
    "            self.uic.label_6.setPixmap(QPixmap(\"Chu_cai_va_so/dau nang.png\"))\n",
    "            print(\"nặng\")\n",
    "            self.thread[4].stop()    \n",
    "        if (number_signal == 11) & (self.cau_hoi_hien_tai == 12):            \n",
    "            self.uic.label_6.clear()\n",
    "            print(\"kết thúc kiểm tra\")\n",
    "            self.thread[4].stop()    \n",
    "            self.trangthai = False\n",
    "            self.thread[5].stop() \n",
    "class capture_video(QThread):\n",
    "    signal = pyqtSignal(np.ndarray)\n",
    "    signal_1 = pyqtSignal(int)\n",
    "    def __init__(self, index):\n",
    "        self.index = index\n",
    "        print(\"start object detection\", self.index)\n",
    "        super().__init__()\n",
    "    \n",
    "    def run(self):\n",
    "        category_index = label_map_util.create_category_index_from_labelmap(ANNOTATION_PATH+'/label_map.pbtxt')\n",
    "        # Setup capture\n",
    "        \n",
    "        cap = cv2.VideoCapture(0)\n",
    "        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        cau_hoi_ke_tiep=1\n",
    "        cau_hoi_hien_tai = 0\n",
    "        noca = 0 #numbers of correct answer\n",
    "        thresh_score = 80 #minimun score để xem đó là 1 nhận diện tốt \n",
    "        while True:\n",
    "            #t = time.time()\n",
    "            ret, frame = cap.read()\n",
    "            image_np = np.array(frame)\n",
    "            image_np_expanded = np.expand_dims(image_np, axis=0)\n",
    "\n",
    "            # Things to try:\n",
    "            # Flip horizontally\n",
    "            # image_np = np.fliplr(image_np).copy()\n",
    "\n",
    "            # Convert image to grayscale\n",
    "            # image_np = np.tile(\n",
    "            #     np.mean(image_np, 2, keepdims=True), (1, 1, 3)).astype(np.uint8)\n",
    "\n",
    "            input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
    "            detections , prediction_dict  = detect_fn(input_tensor)\n",
    "\n",
    "            num_detections = int(detections.pop('num_detections'))\n",
    "            detections = {key: value[0, :num_detections].numpy()\n",
    "                          for key, value in detections.items()}\n",
    "            detections['num_detections'] = num_detections\n",
    "\n",
    "            # detection_classes should be ints.\n",
    "            detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
    "\n",
    "            label_id_offset = 1\n",
    "            image_np_with_detections = image_np.copy()\n",
    "            \n",
    "            #Hàm lấy ra tên và số chỉ số tin cậy (%) đã nhận diện được\n",
    "            def get_classes_name_and_scores(\n",
    "                boxes,\n",
    "                classes,\n",
    "                scores,\n",
    "                category_index,\n",
    "                max_boxes_to_draw=20,\n",
    "                min_score_thresh=.8): # returns bigger than 90% precision\n",
    "                display_str = {}\n",
    "                if not max_boxes_to_draw:\n",
    "                    max_boxes_to_draw = boxes.shape[0]\n",
    "                for i in range(min(max_boxes_to_draw, boxes.shape[0])):\n",
    "                    if scores is None or scores[i] > min_score_thresh:\n",
    "                        if classes[i] in six.viewkeys(category_index):\n",
    "                            display_str['name'] = category_index[classes[i]]['name']\n",
    "                            display_str['score'] = '{}%'.format(int(100 * scores[i]))\n",
    "\n",
    "                return display_str\n",
    "            # Hàm vẽ ra bounding box \n",
    "            viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "                        image_np_with_detections,\n",
    "                        detections['detection_boxes'],\n",
    "                        detections['detection_classes']+label_id_offset,\n",
    "                        detections['detection_scores'],\n",
    "                        category_index,\n",
    "                        use_normalized_coordinates=True,\n",
    "                        max_boxes_to_draw=1,\n",
    "                        min_score_thresh=.5,\n",
    "                        agnostic_mode=False)\n",
    "\n",
    "            \n",
    "\n",
    "            #Hàm lấy ra la\n",
    "            result_predict = get_classes_name_and_scores(\n",
    "              detections['detection_boxes'],\n",
    "              detections['detection_classes']+label_id_offset,\n",
    "              detections['detection_scores'],\n",
    "              category_index)\n",
    "            if (result_predict != {}):\n",
    "                result_name = result_predict['name']\n",
    "                result_score = result_predict['score'].rstrip(\"%\")\n",
    "                result_score = int(result_score)\n",
    "            else:\n",
    "                result_name=\"\"\n",
    "                result_score = 0\n",
    "            # Câu lệnh để đọc kết quả, đọc 10 lần nếu chỉ số tin cậy 10 lần đều cùng trên 1 mức nào đó thì công nhận đó là kết quả đúng\n",
    "            if (result_name == \"B\") & (result_score > thresh_score) & (cau_hoi_hien_tai == 1)  :\n",
    "                noca = noca+1\n",
    "                if (noca == 10):\n",
    "                    print(\"ban da tra loi dung chữ B\")\n",
    "                    noca = 0\n",
    "                    cau_hoi_ke_tiep = 2                \n",
    "            if (result_name == \"C\") & (result_score > thresh_score) & (cau_hoi_hien_tai == 2)  :\n",
    "                noca = noca+1\n",
    "                if (noca == 10):\n",
    "                    print(\"ban da tra loi dung chữ C\")\n",
    "                    noca = 0\n",
    "                    cau_hoi_ke_tiep = 3    \n",
    "            if (result_name == \"A\") & (result_score > thresh_score) & (cau_hoi_hien_tai == 3)  :\n",
    "                noca = noca+1\n",
    "                if (noca == 10):\n",
    "                    print(\"ban da tra loi dung chữ A\")\n",
    "                    noca = 0\n",
    "                    cau_hoi_ke_tiep = 4    \n",
    "            if (result_name == \"E\") & (result_score > thresh_score) & (cau_hoi_hien_tai == 4)  :\n",
    "                noca = noca+1\n",
    "                if (noca == 10):\n",
    "                    print(\"ban da tra loi dung chữ E\")\n",
    "                    noca = 0\n",
    "                    cau_hoi_ke_tiep = 5    \n",
    "            if (result_name == \"D\") & (result_score > thresh_score) & (cau_hoi_hien_tai == 5)  :\n",
    "                noca = noca+1\n",
    "                if (noca == 10):\n",
    "                    print(\"ban da tra loi dung chữ D\")\n",
    "                    noca = 0\n",
    "                    cau_hoi_ke_tiep = 6    \n",
    "            if ret:\n",
    "                self.signal.emit(image_np_with_detections)\n",
    "            if cau_hoi_ke_tiep != cau_hoi_hien_tai :\n",
    "                cau_hoi_hien_tai = cau_hoi_ke_tiep\n",
    "                self.signal_1.emit(cau_hoi_hien_tai)\n",
    "            #print('fps', 1/(time.time()-t))\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                cap.release()\n",
    "                break\n",
    "    def stop(self):\n",
    "        print(\"stop object detection\", self.index)\n",
    "        self.terminate()\n",
    "\n",
    "class speech_to_text(QThread):\n",
    "    signal_2 = pyqtSignal(str)\n",
    "    def __init__(self, index):\n",
    "        self.index = index\n",
    "        print(\"start record\", self.index)\n",
    "        super().__init__()\n",
    "\n",
    "    def run(self):\n",
    "        robot_ear = speech_recognition.Recognizer()\n",
    "        with speech_recognition.Microphone() as mic:\n",
    "            print(\"Robot: Tôi đang lắng nghe bạn\")\n",
    "            audio = robot_ear.record(mic, duration=4)\n",
    "        try:\n",
    "            you = robot_ear.recognize_google(audio, language=\"vi\")\n",
    "        except:\n",
    "            you = \"\"\n",
    "\n",
    "        self.signal_2.emit(you) #gửi kết quả thu được về \n",
    "\n",
    "    def stop(self):\n",
    "        print(\"stop record\", self.index)\n",
    "        self.terminate()\n",
    "\n",
    "class show_video_tra_loi_dung(QThread):\n",
    "    signal_3 = pyqtSignal(np.ndarray)\n",
    "    def __init__(self, index):\n",
    "        self.index = index\n",
    "        print(\"start post video\", self.index)\n",
    "        super().__init__()\n",
    "\n",
    "    def run(self):\n",
    "        cap = cv2.VideoCapture(\"Chu_cai_va_so/CHINH_XAC_4.mp4\")  # 'D:/8.Record video/My Video.mp4'\n",
    "        while True:\n",
    "            ret, cv_vid = cap.read()\n",
    "            if ret:\n",
    "                self.signal_3.emit(cv_vid)\n",
    "    def stop(self):\n",
    "        print(\"stop post video\", self.index)\n",
    "        self.terminate()\n",
    "\n",
    "\n",
    "class Timer_4s(QtCore.QThread):\n",
    "    signal_4 = pyqtSignal(int)\n",
    "\n",
    "    def __init__(self, index=0):\n",
    "        super().__init__()\n",
    "        self.index = index\n",
    "\n",
    "    def run(self):\n",
    "        print('Starting thread...', self.index)\n",
    "        counter = 0\n",
    "        while True:\n",
    "            counter += 1\n",
    "            time.sleep(1)\n",
    "            if counter == 1:\n",
    "                number_signal= 111 #chưa đếm\n",
    "                self.signal_4.emit(number_signal)\n",
    "                print(counter)\n",
    "            if counter == 4:\n",
    "                number_signal = 11 #11 là đếm xong\n",
    "                self.signal_4.emit(number_signal)\n",
    "                print(counter)\n",
    "\n",
    "    def stop(self):\n",
    "        print('Stopping thread...', self.index)\n",
    "        self.terminate()\n",
    "class mediapipe_capture(QtCore.QThread):\n",
    "    signal_5 = pyqtSignal(np.ndarray)\n",
    "    signal_5_1 = pyqtSignal(int)\n",
    "    def __init__(self, index):\n",
    "        self.index = index\n",
    "        print(\"start action recognition thread\", self.index)\n",
    "        super().__init__()\n",
    "    \n",
    "    def run(self):\n",
    "        # 1. New detection variables\n",
    "        sequence = []\n",
    "        sentence = []\n",
    "        predictions = []\n",
    "        threshold = 0.8\n",
    "        count=[]\n",
    "        score_numpy = 0 \n",
    "        score_python =0\n",
    "        cap = cv2.VideoCapture(0)\n",
    "        cau_hoi_ke_tiep = 6\n",
    "        cau_hoi_hien_tai = 6\n",
    "        noca = 0 #numbers of correct answer\n",
    "        thresh_score = 90 #minimun score để xem đó là 1 nhận diện tốt \n",
    "        with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "            while cap.isOpened():\n",
    "                t = time.time()\n",
    "                # Read feed\n",
    "                ret, frame = cap.read()\n",
    "\n",
    "                # Make detections\n",
    "                image, results = mediapipe_detection(frame, holistic)\n",
    "                print(results)\n",
    "\n",
    "                # Draw landmarks\n",
    "                draw_styled_landmarks(image, results)\n",
    "\n",
    "                # 2. Prediction logic\n",
    "                keypoints = extract_keypoints(results)\n",
    "                sequence.append(keypoints)\n",
    "                count.append(keypoints)\n",
    "\n",
    "                # Thuật toán đọc kết quả\n",
    "                if len(sequence) == 30:\n",
    "                    res = model.predict(np.expand_dims(sequence, axis=0))[0]\n",
    "                    print(actions[np.argmax(res)])            \n",
    "                    predictions.append(np.argmax(res)) \n",
    "                    score_numpy = res[np.argmax(res)]  \n",
    "                    score_python = score_numpy.item()\n",
    "                    score_python = score_python *100\n",
    "                    score_python = (round(Decimal(score_python),2))            \n",
    "\n",
    "                    #3. Viz logic\n",
    "                    if np.unique(predictions[-1:])[0]==np.argmax(res): \n",
    "                        if res[np.argmax(res)] > threshold: \n",
    "\n",
    "                            if len(sentence) > 0: \n",
    "                                if actions[np.argmax(res)] != sentence[-1]:\n",
    "                                    sentence.append(actions[np.argmax(res)])\n",
    "                            else:\n",
    "                                sentence.append(actions[np.argmax(res)])\n",
    "                        #Thuật toán so sánh\n",
    "                    if (actions[np.argmax(res)] == \"aw\") & (cau_hoi_hien_tai == 6)  :\n",
    "                        print(\"ban da tra loi dung chữ Ă\")\n",
    "                        cau_hoi_ke_tiep = 7                \n",
    "                    if (actions[np.argmax(res)] == \"ee\")  & (cau_hoi_hien_tai == 7)  :\n",
    "                        print(\"ban da tra loi dung chữ Ê\")\n",
    "                        cau_hoi_ke_tiep = 8    \n",
    "                    if (actions[np.argmax(res)] == \"ow\")  & (cau_hoi_hien_tai == 8)  :\n",
    "                        print(\"ban da tra loi dung chữ Ơ\")\n",
    "                        cau_hoi_ke_tiep = 9    \n",
    "                    if (actions[np.argmax(res)] == \"sac\")  & (cau_hoi_hien_tai == 9)  :\n",
    "                        print(\"ban da tra loi dung dấu sắc\")\n",
    "                        cau_hoi_ke_tiep = 10    \n",
    "                    if (actions[np.argmax(res)] == \"hoi\")  & (cau_hoi_hien_tai == 10)  :\n",
    "                        print(\"ban da tra loi dung dấu hỏi\")\n",
    "                        cau_hoi_ke_tiep = 11    \n",
    "                    if (actions[np.argmax(res)] == \"nang\")  & (cau_hoi_hien_tai == 11)  :\n",
    "                        print(\"ban da tra loi dung dấu nặng\")\n",
    "                        cau_hoi_ke_tiep = 12\n",
    "\n",
    "                    if len(sentence) > 1: \n",
    "                            sentence = sentence[-1:]\n",
    "                elif  len(sequence) > 45 and len(sequence) < 60:\n",
    "                    image = draw_class_on_image(\"STOP\", image)\n",
    "                    cv2.rectangle(image, (120,200), (int((((len(sequence)-30)/20)*110*4)-150),210), (20,20,200), -1)\n",
    "\n",
    "                elif  len(sequence) == 60:\n",
    "                    sequence = []\n",
    "\n",
    "                cv2.rectangle(image, (190,0), (460, 75), (245, 117, 16), -1)\n",
    "                cv2.putText(image, 'Result:', (200,25), \n",
    "                              cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "                cv2.putText(image, ' '.join(sentence), (330,25), \n",
    "                              cv2.FONT_HERSHEY_SIMPLEX, 1, (16,117,245), 2, cv2.LINE_AA)\n",
    "                cv2.putText(image, 'Score:', (200,65), \n",
    "                              cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "                cv2.putText(image, '{}%'.format(score_python), (330,65), \n",
    "                              cv2.FONT_HERSHEY_SIMPLEX, 1, (117,245,16), 2, cv2.LINE_AA)\n",
    "\n",
    "                if ret:\n",
    "                    self.signal_5.emit(image)\n",
    "                if cau_hoi_ke_tiep != cau_hoi_hien_tai :\n",
    "                    cau_hoi_hien_tai = cau_hoi_ke_tiep\n",
    "                    self.signal_5_1.emit(cau_hoi_hien_tai)\n",
    "\n",
    "                if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                    cap.release()\n",
    "                    break\n",
    "    def stop(self):\n",
    "        print(\"start action recognition thread\", self.index)\n",
    "        self.terminate()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app = QApplication(sys.argv)\n",
    "    main_win = MainWindow()\n",
    "    main_win.show()\n",
    "    sys.exit(app.exec())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7720890",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cau_hoi_hien_tai' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14568\\2386636571.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcau_hoi_hien_tai\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'cau_hoi_hien_tai' is not defined"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:combine_env6] *",
   "language": "python",
   "name": "conda-env-combine_env6-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
